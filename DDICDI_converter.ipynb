{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "067ce98c-9018-4f4a-b96c-a010acbd7e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import pandas as pd\n",
    "import pyreadstat as pyr\n",
    "import json\n",
    "import numpy as np\n",
    "from spss_import import read_sav \n",
    "pd.set_option('display.max_rows', 2500)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645f1dfc-d9a0-447f-b6c5-262f256f2e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#help(pyr.read_sav)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b3ad9d-5958-473e-a2ae-1ad0e9559984",
   "metadata": {},
   "outputs": [],
   "source": [
    "spssfile = f\"files/SPSS_Example2.sav\"\n",
    "df, df_meta = read_sav(spssfile)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1511ff74-4255-4135-aacd-87a92c7c8de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "spssfile2 = f\"files/ESS-Data-Wizard-subset-2023-10-23.dta\"\n",
    "df2, df2_meta = read_sav(spssfile2)\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef21f4c-43c0-423e-8eb6-958cef0f2cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def create_variable_view(df_meta):\n",
    "    # Extract the attributes from df_meta\n",
    "    label = df_meta.column_names_to_labels\n",
    "    values = df_meta.variable_value_labels\n",
    "    missing = df_meta.missing_ranges\n",
    "    format = df_meta.original_variable_types\n",
    "    measure = df_meta.variable_measure\n",
    "\n",
    "    # Convert dictionaries into individual dataframes\n",
    "    df_label = pd.DataFrame(list(label.items()), columns=['name', 'label'])\n",
    "    df_format = pd.DataFrame(list(format.items()), columns=['name', 'format'])\n",
    "    df_measure = pd.DataFrame(list(measure.items()), columns=['name', 'measure'])\n",
    "\n",
    "    # For values and missing, handle them differently due to dictionaries/lists inside\n",
    "    df_values_list = [{'name': k, 'values': str(v)} for k, v in values.items()]  # Convert values to string\n",
    "    df_values = pd.DataFrame(df_values_list)\n",
    "\n",
    "    df_missing_list = [{'name': k, 'missing': str(v)} for k, v in missing.items()]  # Convert missing values to string\n",
    "    df_missing = pd.DataFrame(df_missing_list)\n",
    "\n",
    "    # Merge dataframes on the 'name' column\n",
    "    variable_view = df_label\n",
    "    if not df_values.empty:\n",
    "        variable_view = variable_view.merge(df_values, on='name', how='outer')\n",
    "    \n",
    "    if not df_missing.empty:\n",
    "        variable_view = variable_view.merge(df_missing, on='name', how='outer')\n",
    "\n",
    "    variable_view = variable_view \\\n",
    "        .merge(df_format, on='name', how='outer') \\\n",
    "        .merge(df_measure, on='name', how='outer')\n",
    "\n",
    "    # Ensure 'values' and 'missing' columns are present\n",
    "    if 'values' not in variable_view.columns:\n",
    "        variable_view['values'] = pd.NA\n",
    "\n",
    "    if 'missing' not in variable_view.columns:\n",
    "        variable_view['missing'] = pd.NA\n",
    "\n",
    "    return variable_view[['name', 'format', 'measure', 'label', 'values', 'missing']]\n",
    "\n",
    "\n",
    "create_variable_view(df_meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b94eae7-09cb-4998-a0c2-ce998b7e42e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def create_variable_view2(df_meta):\n",
    "    # Extract the attributes from df_meta\n",
    "    label = df_meta.column_names_to_labels\n",
    "    values = df_meta.variable_value_labels\n",
    "\n",
    "    # Convert user-defined missing values to the desired format\n",
    "    missing = {}\n",
    "    for key, vals in df_meta.missing_user_values.items():\n",
    "        missing[key] = [{\"lo\": val, \"hi\": val} for val in vals]\n",
    "\n",
    "    format = df_meta.original_variable_types\n",
    "    measure = df_meta.variable_measure\n",
    "\n",
    "    # Convert dictionaries into individual dataframes\n",
    "    df_label = pd.DataFrame(list(label.items()), columns=['name', 'label'])\n",
    "    df_format = pd.DataFrame(list(format.items()), columns=['name', 'format'])\n",
    "    df_measure = pd.DataFrame(list(measure.items()), columns=['name', 'measure'])\n",
    "\n",
    "    # For values and missing, handle them differently due to dictionaries/lists inside\n",
    "    df_values_list = [{'name': k, 'values': str(v)} for k, v in values.items()]  # Convert values to string\n",
    "    df_values = pd.DataFrame(df_values_list)\n",
    "\n",
    "    df_missing_list = [{'name': k, 'missing': str(v)} for k, v in missing.items()]  # Convert missing values to string\n",
    "    df_missing = pd.DataFrame(df_missing_list)\n",
    "\n",
    "    # Merge dataframes on the 'name' column\n",
    "    variable_view = df_label\n",
    "    if not df_values.empty:\n",
    "        variable_view = variable_view.merge(df_values, on='name', how='outer')\n",
    "    else:\n",
    "        variable_view['values'] = pd.NA\n",
    "    \n",
    "    if not df_missing.empty:\n",
    "        variable_view = variable_view.merge(df_missing, on='name', how='outer')\n",
    "    else:\n",
    "        variable_view['missing'] = pd.NA\n",
    "\n",
    "    variable_view = variable_view \\\n",
    "        .merge(df_format, on='name', how='outer') \\\n",
    "        .merge(df_measure, on='name', how='outer')\n",
    "\n",
    "    # Ensure 'values' and 'missing' columns are present\n",
    "    if 'values' not in variable_view.columns:\n",
    "        variable_view['values'] = pd.NA\n",
    "\n",
    "    if 'missing' not in variable_view.columns:\n",
    "        variable_view['missing'] = pd.NA\n",
    "\n",
    "    return variable_view\n",
    "\n",
    "create_variable_view2(df2_meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4e5dd9-5dc8-4a1f-bc5c-9c3efc4bd2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Label = df_meta.column_names_to_labels\n",
    "Values = df_meta.variable_value_labels\n",
    "Missing = df_meta.missing_ranges\n",
    "Format = df_meta.original_variable_types\n",
    "Measure = df_meta.variable_measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215309e3-3179-4bbe-876c-9bc5d1ead7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_InstanceVariable(df_meta):\n",
    "    json_ld_data = []\n",
    "\n",
    "    # Iterate through column names and associated index\n",
    "    for idx, variable in enumerate(df_meta.column_names):\n",
    "        elements = {\n",
    "            \"@id\": f\"#{variable}\",\n",
    "            \"@type\": \"InstanceVariable\",\n",
    "            \"name\": variable,\n",
    "            \"displayLabel\": df_meta.column_labels[idx],\n",
    "            \"hasIntendedDataType\": df_meta.original_variable_types[variable],\n",
    "            'takesSubstantiveConceptsFrom' : f\"#substantiveConceptualDomain-{variable}\"\n",
    "        }\n",
    "        # Check if variable has sentinel concepts\n",
    "        if variable in df_meta.missing_ranges or (len(df_meta.missing_ranges) == 0 and variable in df_meta.missing_user_values):\n",
    "            elements['takesSentinelConceptsFrom'] = f\"#sentinelConceptualDomain-{variable}\"\n",
    "\n",
    "        json_ld_data.append(elements)\n",
    "\n",
    "    return json_ld_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2bee657-7a42-4a15-ac1d-0fd4e4e2c4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MeasureComponent\n",
    "def generate_MeasureComponent(df_meta):\n",
    "    json_ld_data = []\n",
    "    for x, variable in enumerate(df_meta.column_names[1:]):\n",
    "        elements = {\n",
    "            \"@id\": f\"#measureComponent-{variable}\",\n",
    "            \"@type\": \"MeasureComponent\",\n",
    "            \"isDefinedBy\": f\"#{variable}\"\n",
    "        }\n",
    "        json_ld_data.append(elements)\n",
    "\n",
    "    return json_ld_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df52788f-e446-49ea-8f55-0c22db6bbb86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MeasureComponent2\n",
    "def generate_MeasureComponent2(df_meta, varlist=None):\n",
    "    json_ld_data = []\n",
    "    for x, variable in enumerate(df_meta.column_names):\n",
    "        if variable not in varlist:\n",
    "            elements = {\n",
    "                \"@id\": f\"#measureComponent-{variable}\",\n",
    "                \"@type\": \"MeasureComponent\",\n",
    "                \"isDefinedBy\": f\"#{variable}\"\n",
    "            }\n",
    "            json_ld_data.append(elements)\n",
    "\n",
    "    return json_ld_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc33340e-7f92-45be-a0ce-69d144d11ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IdentifierComponent\n",
    "def generate_IdentifierComponent(df_meta):\n",
    "    json_ld_data = []\n",
    "    elements = {\n",
    "        \"@id\": f\"#identifierComponent-{df_meta.column_names[0]}\",\n",
    "        \"@type\": \"IdentifierComponent\",\n",
    "        \"isDefinedBy\": f\"#{df_meta.column_names[0]}\"\n",
    "    }\n",
    "    json_ld_data.append(elements)\n",
    "\n",
    "    return json_ld_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e806d81-5be7-4380-89a4-249fe91b3c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IdentifierComponent2\n",
    "def generate_IdentifierComponent2(df_meta, varlist=None):\n",
    "    json_ld_data = []\n",
    "    for x, variable in enumerate(df_meta.column_names):\n",
    "        if variable in varlist:\n",
    "            elements = {\n",
    "                \"@id\": f\"#identifierComponent-{variable}\",\n",
    "                \"@type\": \"IdentifierComponent\",\n",
    "                \"isDefinedBy\": f\"#{variable}\"\n",
    "            }\n",
    "            json_ld_data.append(elements)\n",
    "\n",
    "    return json_ld_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bfafd4a-7380-4d15-918c-91861bdefd85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# logicalRecord\n",
    "def generate_LogicalRecord(df_meta):\n",
    "    json_ld_data = []\n",
    "    elements = {\n",
    "        \"@id\": f\"#logicalRecord\",\n",
    "        \"@type\": \"LogicalRecord\",\n",
    "        \"organizes\": f\"#wideDataSet\"\n",
    "    }\n",
    "    has = []    \n",
    "    for x, variable in enumerate(df_meta.column_names):\n",
    "        has.append(f\"#{variable}\")\n",
    "    elements['has'] = has\n",
    "    json_ld_data.append(elements)\n",
    "    return json_ld_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8b3b23-f5ce-4f79-b894-ae4687a6ecd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PhysicalDataset\n",
    "def generate_PhysicalDataset(df_meta, spssfile):\n",
    "    json_ld_data = []\n",
    "    elements = {\n",
    "        \"@id\": f\"#physicalDataset\",\n",
    "        \"@type\": \"PhysicalDataset\",\n",
    "        \"formats\": \"#dataStore\",\n",
    "        \"physicalFileName\": spssfile\n",
    "    }\n",
    "    has = [\"#physicalRecordSegment\"]\n",
    "    elements['has'] = has    \n",
    "    json_ld_data.append(elements)\n",
    "    return json_ld_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79e59ce-62fb-4a29-b3f0-15c892a843d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataStore\n",
    "def generate_DataStore(df_meta):\n",
    "    json_ld_data = []\n",
    "    elements = {\n",
    "        \"@id\": f\"#dataStore\",\n",
    "        \"@type\": \"DataStore\",\n",
    "        \"recordCount\": df_meta.number_rows\n",
    "    }\n",
    "    has = [\"#logicalRecord\"]\n",
    "    elements['has'] = has   \n",
    "    \n",
    "    json_ld_data.append(elements)\n",
    "    return json_ld_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69090b36-4609-467d-b4c2-013f9b8802de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WideDataSet\n",
    "def generate_WideDataSet(df_meta):\n",
    "    json_ld_data = []\n",
    "    elements = {\n",
    "        \"@id\": f\"#wideDataSet\",\n",
    "        \"@type\": \"WideDataSet\",\n",
    "        \"isStructuredBy\": \"#wideDataStructure\"\n",
    "    }\n",
    "    \n",
    "    json_ld_data.append(elements)\n",
    "    return json_ld_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38f3655-4365-4f09-9634-33ca36661137",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WideDataStructure\n",
    "def generate_WideDataStructure(df_meta):\n",
    "    json_ld_data = []\n",
    "    elements = {\n",
    "        \"@id\": f\"#wideDataStructure\",\n",
    "        \"@type\": \"WideDataStructure\",\n",
    "    }\n",
    "    has = [\"#primaryKey\", f\"#identifierComponent-{df_meta.column_names[0]}\"]\n",
    "    \n",
    "    for x, variable in enumerate(df_meta.column_names[1:]):\n",
    "        has.append(f\"#measureComponent-{variable}\")\n",
    "    elements['has'] = has\n",
    "        \n",
    "    json_ld_data.append(elements)\n",
    "    return json_ld_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875eb435-0ffb-405b-8889-0804167b778d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WideDataStructure2\n",
    "def generate_WideDataStructure2(df_meta, varlist=None):\n",
    "    json_ld_data = []\n",
    "    elements = {\n",
    "        \"@id\": f\"#wideDataStructure\",\n",
    "        \"@type\": \"WideDataStructure\",\n",
    "    }\n",
    "    has = [\"#primaryKey\"]\n",
    "    \n",
    "    for x, variable in enumerate(df_meta.column_names):\n",
    "        if variable in varlist:\n",
    "            has.append(f\"#identifierComponent-{variable}\")\n",
    "        else:\n",
    "            has.append(f\"#measureComponent-{variable}\")\n",
    "    elements['has'] = has\n",
    "        \n",
    "    json_ld_data.append(elements)\n",
    "    return json_ld_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148f6ab8-742c-4528-a42a-040ad70bbe36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PrimaryKey\n",
    "def generate_PrimaryKey(df_meta):\n",
    "    json_ld_data = []\n",
    "    elements = {\n",
    "        \"@id\": \"#primaryKey\",\n",
    "        \"@type\": \"PrimaryKey\",\n",
    "        \"isComposedOf\": \"#primaryKeyComponent\"\n",
    "    }\n",
    "        \n",
    "    json_ld_data.append(elements)\n",
    "    return json_ld_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ee965d-e024-44b4-b59e-9b835321473c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PrimaryKeyComponent\n",
    "def generate_PrimaryKeyComponent(df_meta):\n",
    "    json_ld_data = []\n",
    "    elements = {\n",
    "        \"@id\": \"#primaryKeyComponent\",\n",
    "        \"@type\": \"PrimaryKeyComponent\",\n",
    "        \"correspondsTo\": f\"#identifierComponent-{df_meta.column_names[0]}\"\n",
    "    }\n",
    "        \n",
    "    json_ld_data.append(elements)\n",
    "    return json_ld_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5993b67d-26ab-4fef-a6d0-5aa873207829",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PrimaryKeyComponent2\n",
    "def generate_PrimaryKeyComponent2(df_meta, varlist=None):\n",
    "    json_ld_data = []\n",
    "    elements = {\n",
    "        \"@id\": \"#primaryKeyComponent\",\n",
    "        \"@type\": \"PrimaryKeyComponent\",\n",
    "    }\n",
    "    has = []    \n",
    "    for variable in varlist:\n",
    "        has.append(f\"#identifierComponent-{variable}\")\n",
    "    \n",
    "    elements['correspondsTo'] = has      \n",
    "    json_ld_data.append(elements)\n",
    "    return json_ld_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843cda54-ac03-42cd-bd2f-be655550aa18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PhysicalRecordSegment\n",
    "def generate_PhysicalRecordSegment(df_meta):\n",
    "    json_ld_data = []\n",
    "    elements = {\n",
    "        \"@id\": f\"#physicalRecordSegment\",\n",
    "        \"@type\": \"PhysicalRecordSegment\",\n",
    "        \"mapsTo\": \"#logicalRecord\",\n",
    "    }\n",
    "    has = [\"#physicalSegmentLayout\"]\n",
    "    elements['has'] = has    \n",
    "    \n",
    "    json_ld_data.append(elements)\n",
    "    return json_ld_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79bda048-f7a5-42b1-8d0c-1c3d01e905c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PhysicalSegmentLayout\n",
    "def generate_PhysicalSegmentLayout(df_meta):\n",
    "    json_ld_data = []\n",
    "    elements = {\n",
    "        \"@id\": f\"#physicalSegmentLayout\",\n",
    "        \"@type\": \"PhysicalSegmentLayout\",\n",
    "        \"formats\": \"#logicalRecord\",\n",
    "        \"isDelimited\": \"false\",\n",
    "        \"delimiter\": \"\",\n",
    "    }\n",
    "    has = []    \n",
    "    for x, variable in enumerate(df_meta.column_names):\n",
    "        has.append(f\"#valueMapping-{variable}\")\n",
    "        has.append(f\"#valueMappingPosition-{variable}\")\n",
    "    elements['has'] = has    \n",
    "    json_ld_data.append(elements)\n",
    "    return json_ld_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095b4f75-d942-4528-9292-7f81ec204781",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ValueMapping\n",
    "def generate_ValueMapping(df, df_meta):\n",
    "    json_ld_data = []\n",
    "\n",
    "    # Iterate through column names and associated index\n",
    "    for idx, variable in enumerate(df_meta.column_names):\n",
    "        elements = {\n",
    "            \"@id\": f\"#valueMapping-{variable}\",\n",
    "            \"@type\": \"ValueMapping\",\n",
    "        }\n",
    "        datapoints = []\n",
    "        for i, x in enumerate(df[variable]):\n",
    "            datapoints.append(f\"#{variable}-dataPoint-{i}\")\n",
    "        elements['formats'] = datapoints\n",
    "\n",
    "        json_ld_data.append(elements)\n",
    "\n",
    "    return json_ld_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fddcef52-5e6a-4650-a21c-31b0c93094b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ValueMappingPosition\n",
    "def generate_ValueMappingPosition(df_meta):\n",
    "    json_ld_data = []\n",
    "\n",
    "    # Iterate through column names and associated index\n",
    "    for idx, variable in enumerate(df_meta.column_names):\n",
    "        elements = {\n",
    "            \"@id\": f\"#valueMappingPosition-{variable}\",\n",
    "            \"@type\": \"ValueMappingPosition\",\n",
    "            \"value\": idx,\n",
    "            \"indexes\": f\"#valueMapping-{variable}\"\n",
    "        }\n",
    "        json_ld_data.append(elements)\n",
    "\n",
    "    return json_ld_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068797fd-9785-47a0-97ef-fc65d8b267da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataPoint\n",
    "def generate_DataPoint(df, df_meta):\n",
    "    json_ld_data = []\n",
    "\n",
    "    # Iterate through column names and associated index\n",
    "    for variable in (df_meta.column_names):\n",
    "        for idx, value in enumerate(df[variable]):\n",
    "            elements = {\n",
    "                \"@id\": f\"#{variable}-dataPoint-{idx}\",\n",
    "                \"@type\": \"DataPoint\",\n",
    "                \"isDescribedBy\": f\"#{variable}-instanceValue-{idx}\"\n",
    "            }\n",
    "\n",
    "            json_ld_data.append(elements)\n",
    "\n",
    "    return json_ld_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0327ea-d9db-442a-bbb4-34a708a37fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataPointPosition\n",
    "def generate_DataPointPosition(df, df_meta):\n",
    "    json_ld_data = []\n",
    "\n",
    "    # Iterate through column names and associated index\n",
    "    for variable in (df_meta.column_names):\n",
    "        for idx, value in enumerate(df[variable]):\n",
    "            elements = {\n",
    "                \"@id\": f\"#{variable}-dataPointPosition-{idx}\",\n",
    "                \"@type\": \"DataPointPosition\",\n",
    "                \"value\": idx,\n",
    "                \"indexes\": f\"#{variable}-dataPoint-{idx}\"\n",
    "            }\n",
    "\n",
    "            json_ld_data.append(elements)\n",
    "\n",
    "    return json_ld_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "099d692b-f505-4070-97d3-b1346e1f31eb",
   "metadata": {},
   "outputs": [],
   "source": [
    " # SubstantiveValueDomain\n",
    "def generate_SubstantiveValueDomain(df_meta):\n",
    "    json_ld_data = []\n",
    "    for x, variable in enumerate(df_meta.variable_value_labels):\n",
    "        elements = {\n",
    "            \"@id\": f\"#substantiveValueDomain-{variable}\",\n",
    "            \"@type\": \"SubstantiveValueDomain\",\n",
    "            \"takesValuesFrom\": f\"#codelist.{variable}\"\n",
    "        }\n",
    "        json_ld_data.append(elements)\n",
    "\n",
    "    return json_ld_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783c761f-ab0a-4092-9f54-c32fc9352887",
   "metadata": {},
   "outputs": [],
   "source": [
    "# InstanceValue\n",
    "def generate_InstanceValue(df, df_meta):\n",
    "    json_ld_data = []\n",
    "\n",
    "    # Iterate through column names and associated index\n",
    "    for variable in (df_meta.column_names):\n",
    "        for idx, value in enumerate(df[variable]):\n",
    "            elements = {\n",
    "                \"@id\": f\"#{variable}-instanceValue-{idx}\",\n",
    "                \"@type\": \"InstanceValue\",\n",
    "                \"content\": value,\n",
    "                \"isStoredIn\": f\"#{variable}-dataPoint-{idx}\"\n",
    "            }\n",
    "\n",
    "            json_ld_data.append(elements)\n",
    "\n",
    "    return json_ld_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366f2403-ba48-440b-94c2-12cf5363e491",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Codelist\n",
    "def generate_Codelist(df_meta):\n",
    "    json_ld_data = []\n",
    "    for x, variable in enumerate(df_meta.variable_value_labels.items()):\n",
    "        elements = {\n",
    "            \"@id\": f\"#codelist-{variable[x]}\",\n",
    "            \"@type\": \"Codelist\",\n",
    "        }\n",
    "        has = []\n",
    "        your_dict = variable[1]\n",
    "        # Loop through the dictionary and extract the keys\n",
    "        for key in your_dict.keys():\n",
    "            codes = {\n",
    "                \"@id\": f\"#code-{key}-{variable[x]}\"\n",
    "            }\n",
    "            has.append(codes)\n",
    "        elements['has'] = has    \n",
    "\n",
    "        json_ld_data.append(elements)\n",
    "\n",
    "    return json_ld_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8256bb-059c-4600-8e96-fa2fce198335",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code\n",
    "def generate_Code(df_meta):\n",
    "    json_ld_data = []\n",
    "    for x, variable in enumerate(df_meta.variable_value_labels.items()):\n",
    "        your_dict = variable[1]\n",
    "        # Loop through the dictionary and extract the keys\n",
    "        for key, value in your_dict.items():\n",
    "            elements = {\n",
    "                \"@id\": f\"#code-{key}-{variable[x]}\",\n",
    "                \"@type\": \"Code\",\n",
    "            }\n",
    "            has = []\n",
    "            codes = {\n",
    "                \"@id\": f\"#{key}\"\n",
    "            }\n",
    "            has.append(codes)\n",
    "            elements['denotes'] = has\n",
    "\n",
    "            has = []\n",
    "            codes = {\n",
    "                \"@id\": f\"#{value}\"\n",
    "            }\n",
    "            has.append(codes)\n",
    "            elements['uses'] = has \n",
    "\n",
    "            json_ld_data.append(elements)\n",
    "\n",
    "    return json_ld_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e07a42-50e8-4eeb-a1d3-2ef1d83b3846",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SubstantiveConceptScheme\n",
    "def generate_SubstantiveConceptScheme(df_meta):\n",
    "    json_ld_data = []\n",
    "\n",
    "    # Determine the relevant variables based on the presence of missing values\n",
    "    relevant_variables = df_meta.missing_ranges if len(df_meta.missing_ranges) > 0 else df_meta.missing_user_values\n",
    "\n",
    "    for variable_name, values_dict in df_meta.variable_value_labels.items():\n",
    "        elements = {\n",
    "            \"@id\": f\"#substantiveConceptScheme-{variable_name}\",\n",
    "            \"@type\": \"skos:ConceptScheme\",\n",
    "        }\n",
    "\n",
    "        excluded_values = set()\n",
    "\n",
    "        # Check if variable_name is in relevant_variables\n",
    "        if variable_name in relevant_variables:\n",
    "            \n",
    "            # If the relevant variable data is based on ranges and contains dictionaries\n",
    "            if isinstance(relevant_variables[variable_name], list) and all(isinstance(item, dict) for item in relevant_variables[variable_name]):\n",
    "                for dict_range in relevant_variables[variable_name]:\n",
    "                    lo_is_numeric = isinstance(dict_range['lo'], (int, float)) or (\n",
    "                        isinstance(dict_range['lo'], str) and dict_range['lo'].isnumeric()\n",
    "                    )\n",
    "                    hi_is_numeric = isinstance(dict_range['hi'], (int, float)) or (\n",
    "                        isinstance(dict_range['hi'], str) and dict_range['hi'].isnumeric()\n",
    "                    )\n",
    "\n",
    "                    if lo_is_numeric and hi_is_numeric:\n",
    "                        excluded_values.update(\n",
    "                            range(int(float(dict_range['lo'])), int(float(dict_range['hi'])) + 1)\n",
    "                        )\n",
    "                    elif isinstance(dict_range['lo'], str):\n",
    "                        excluded_values.add(dict_range['lo'])\n",
    "                    else:\n",
    "                        print(f\"Warning: Unsupported 'lo' value: {dict_range['lo']}\")\n",
    "\n",
    "            # If the relevant variable data contains strings (user-defined missing values)\n",
    "            elif isinstance(relevant_variables[variable_name], list):\n",
    "                excluded_values.update(set(map(str, relevant_variables[variable_name])))\n",
    "\n",
    "        # Use list comprehension to generate the hasTopConcept list\n",
    "        has_top_concept = [\n",
    "            f\"#{variable_name}-concept-{value}\"\n",
    "            for value in values_dict.keys()\n",
    "            if str(value) not in excluded_values\n",
    "        ]\n",
    "\n",
    "        # Only add to json_ld_data if has_top_concept list is not empty\n",
    "        if has_top_concept:\n",
    "            elements['skos:hasTopConcept'] = has_top_concept\n",
    "            json_ld_data.append(elements)\n",
    "\n",
    "    return json_ld_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1733c8a-5e9b-4c73-8a40-4b6d237f473f",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_meta.missing_ranges)\n",
    "display(df2_meta.missing_user_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2af43d-dd38-4322-8603-bb5577f980c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ValueAndConceptDescription\n",
    "def generate_ValueAndConceptDescription(df_meta):\n",
    "    # Determine the relevant variables based on the presence of missing values\n",
    "    relevant_variables = {}\n",
    "    if df_meta.missing_ranges:\n",
    "        relevant_variables = df_meta.missing_ranges\n",
    "    elif df_meta.missing_user_values:\n",
    "        relevant_variables = df_meta.missing_user_values\n",
    "    \n",
    "    json_ld_data = []\n",
    "\n",
    "    for variable in df_meta.column_names:\n",
    "        # Add substantiveValueAndConceptDescription for every variable\n",
    "        json_ld_data.append({\n",
    "            \"@id\": f\"#substantiveValueAndConceptDescription-{variable}\",\n",
    "            \"@type\": \"ValueAndConceptDescription\",\n",
    "            \"classificationLevel\": f\"{df_meta.variable_measure[variable]}\"\n",
    "        })\n",
    "\n",
    "        # Add sentinelValueAndConceptDescription only if the condition is met\n",
    "        if variable in relevant_variables:\n",
    "            values = relevant_variables[variable]\n",
    "            if isinstance(values[0], dict):  # Check if the values are dictionaries\n",
    "                all_lo_values = [d['lo'] for d in values]\n",
    "                all_hi_values = [d['hi'] for d in values]\n",
    "                min_val = min(all_lo_values)\n",
    "                max_val = max(all_hi_values)\n",
    "            else:\n",
    "                min_val, max_val = min(values), max(values)\n",
    "\n",
    "            json_ld_data.append({\n",
    "                \"@id\": f\"#sentinelValueAndConceptDescription-{variable}\",\n",
    "                \"@type\": \"ValueAndConceptDescription\",\n",
    "                \"description\": str(values),\n",
    "                \"minimumValueExclusive\": str(min_val),\n",
    "                \"maximumValueExclusive\": str(max_val),\n",
    "            })\n",
    "\n",
    "    return json_ld_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011ce2d9-6448-4c22-8da0-059a6bb62ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SubstantiveConceptualDomain\n",
    "def generate_SubstantiveConceptualDomain(df_meta):\n",
    "    json_ld_data = []\n",
    "    \n",
    "    for var in df_meta.column_names:\n",
    "        elements = {\n",
    "            \"@id\": f\"#substantiveConceptualDomain-{var}\",\n",
    "            \"@type\": \"SubstantiveConceptualDomain\",\n",
    "            \"isDescribedBy\" : f\"#substantiveValueAndConceptDescription-{var}\"\n",
    "        }\n",
    "        \n",
    "        if var in df_meta.variable_value_labels:\n",
    "            elements[\"takesConceptsFrom\"] = f\"#substantiveConceptScheme-{var}\"\n",
    "\n",
    "        json_ld_data.append(elements)\n",
    "\n",
    "    return json_ld_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24d6aeb-e246-4381-b8b4-458ee2f2b48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SentinelConceptualDomain\n",
    "def generate_SentinelConceptualDomain(df_meta):\n",
    "    json_ld_data = []\n",
    "\n",
    "    # Determine the relevant variables based on the presence of missing values\n",
    "    relevant_variables = df_meta.missing_ranges if len(df_meta.missing_ranges) > 0 else df_meta.missing_user_values\n",
    "\n",
    "    for variable in relevant_variables:\n",
    "        elements = {\n",
    "            \"@id\": f\"#sentinelConceptualDomain-{variable}\",\n",
    "            \"@type\": \"SentinelConceptualDomain\",\n",
    "            \"isDescribedBy\": f\"#sentinelValueAndConceptDescription-{variable}\",\n",
    "        }\n",
    "        if variable in df_meta.variable_value_labels.keys():\n",
    "            elements[\"takesConceptsFrom\"] = f\"#sentinelConceptScheme-{variable}\"\n",
    "            \n",
    "        json_ld_data.append(elements)\n",
    "\n",
    "    return json_ld_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5b042c-1b16-48d8-ad16-6bc6c4ef33fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meta.missing_ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc984416-e011-4e40-b337-18eaa85f4d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_meta.missing_user_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf3ca73-bc0a-4279-9b55-0e0a1e32ca49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate_SentinelConceptScheme\n",
    "def generate_SentinelConceptScheme(df_meta):\n",
    "    json_ld_data = []\n",
    "\n",
    "    # Determine the relevant variables based on the presence of missing values\n",
    "    relevant_variables = df_meta.missing_ranges if len(df_meta.missing_ranges) > 0 else df_meta.missing_user_values\n",
    "\n",
    "    def is_value_in_range(value, ranges):\n",
    "        \"\"\"Check if a value is in any of the given ranges.\"\"\"\n",
    "        for range_dict in ranges:\n",
    "            if range_dict['lo'] <= value <= range_dict['hi']:\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    for variable_name, values_dict in df_meta.variable_value_labels.items():\n",
    "        elements = {\n",
    "            \"@id\": f\"#sentinelConceptScheme-{variable_name}\",\n",
    "            \"@type\": \"skos:ConceptScheme\",\n",
    "        }\n",
    "\n",
    "        has_top_concept = []\n",
    "        \n",
    "        if variable_name in relevant_variables:\n",
    "            if variable_name in df_meta.missing_ranges:\n",
    "                # Use list comprehension to generate the hasTopConcept list\n",
    "                has_top_concept = [\n",
    "                    f\"#{variable_name}-concept-{value}\"\n",
    "                    for value in values_dict.keys()\n",
    "                    if is_value_in_range(value, df_meta.missing_ranges[variable_name])\n",
    "                ]\n",
    "            else:\n",
    "                excluded_values = set(df_meta.missing_user_values[variable_name])\n",
    "                has_top_concept = [\n",
    "                    f\"#{variable_name}-concept-{value}\"\n",
    "                    for value in values_dict.keys()\n",
    "                    if value in excluded_values\n",
    "                ]\n",
    "        \n",
    "        # Add the hasTopConcept list to elements\n",
    "        elements['skos:hasTopConcept'] = has_top_concept\n",
    "        \n",
    "        json_ld_data.append(elements)\n",
    "\n",
    "    return json_ld_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9c6f0e-f5b7-4fe7-81c2-d1a35d6d5478",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concept\n",
    "def generate_Concept(df_meta):\n",
    "    def is_value_in_excluded_ranges(value, excluded_ranges):\n",
    "        if isinstance(value, (int, float)):\n",
    "            return value in excluded_ranges\n",
    "        elif isinstance(value, str):\n",
    "            return value in excluded_ranges\n",
    "        return False\n",
    "\n",
    "    json_ld_data = []\n",
    "\n",
    "    # Convert user-defined missing values to the desired format\n",
    "    if df_meta.missing_user_values:\n",
    "        missing = {}\n",
    "        for key, vals in df_meta.missing_user_values.items():\n",
    "            missing[key] = [{\"lo\": val, \"hi\": val} for val in vals]\n",
    "    else:\n",
    "        missing = df_meta.missing_ranges\n",
    "\n",
    "    for variable_name, values_dict in df_meta.variable_value_labels.items():\n",
    "        # Check if variable_name is in missing and, if so, generate the excluded_ranges\n",
    "        excluded_ranges = set()\n",
    "        if variable_name in missing:\n",
    "            for dict_range in missing[variable_name]:\n",
    "                lo_is_numeric = isinstance(dict_range['lo'], (int, float)) or (\n",
    "                    isinstance(dict_range['lo'], str) and dict_range['lo'].isnumeric()\n",
    "                )\n",
    "                hi_is_numeric = isinstance(dict_range['hi'], (int, float)) or (\n",
    "                    isinstance(dict_range['hi'], str) and dict_range['hi'].isnumeric()\n",
    "                )\n",
    "\n",
    "                if lo_is_numeric and hi_is_numeric:\n",
    "                    # Case: 'lo' and 'hi' can be converted to int\n",
    "                    excluded_ranges.update(\n",
    "                        range(int(float(dict_range['lo'])), int(float(dict_range['hi'])) + 1)\n",
    "                    )\n",
    "                elif isinstance(dict_range['lo'], str) and dict_range['lo'] == dict_range['hi']:\n",
    "                    # Case: 'lo' and 'hi' are the same non-numeric string\n",
    "                    excluded_ranges.add(dict_range['lo'])\n",
    "                else:\n",
    "                    print(f\"Warning: Unsupported 'lo' value: {dict_range['lo']}\")\n",
    "\n",
    "        # Iterate through values_dict and create elements, taking into account excluded_keys\n",
    "        for key, value in values_dict.items():\n",
    "            elements = {\n",
    "                \"@id\": f\"#{variable_name}-concept-{key}\",\n",
    "                \"@type\": \"skos:Concept\",\n",
    "                \"notation\": key,\n",
    "                \"prefLabel\": f\"{value}\",\n",
    "            }\n",
    "\n",
    "            # Add the inScheme key to elements based on whether the key is in excluded_ranges\n",
    "            if is_value_in_excluded_ranges(key, excluded_ranges):\n",
    "                elements['inScheme'] = f\"#sentinelConceptScheme-{variable_name}\"\n",
    "            else:\n",
    "                elements['inScheme'] = f\"#substantiveConceptScheme-{variable_name}\"\n",
    "\n",
    "            # Append elements to json_ld_data inside the loop\n",
    "            json_ld_data.append(elements)\n",
    "\n",
    "    return json_ld_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43d0eb8-8f69-433d-8ad2-2f2299d074b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate JSON-LD\n",
    "InstanceVariable = generate_InstanceVariable(df_meta)\n",
    "#SubstantiveValueDomain = generate_SubstantiveValueDomain(df_meta)\n",
    "SubstantiveConceptualDomain = generate_SubstantiveConceptualDomain(df_meta)\n",
    "SentinelConceptualDomain = generate_SentinelConceptualDomain(df_meta)\n",
    "ValueAndConceptDescription = generate_ValueAndConceptDescription(df_meta)\n",
    "SubstantiveConceptScheme = generate_SubstantiveConceptScheme(df_meta)\n",
    "SentinelConceptScheme = generate_SentinelConceptScheme(df_meta)\n",
    "Concept = generate_Concept(df_meta)\n",
    "#Codelist = generate_Codelist(df_meta)\n",
    "#Code = generate_Code(df_meta)\n",
    "LogicalRecord = generate_LogicalRecord(df_meta)\n",
    "PhysicalDataset = generate_PhysicalDataset(df_meta, spssfile)\n",
    "PhysicalRecordSegment = generate_PhysicalRecordSegment(df_meta)\n",
    "PhysicalSegmentLayout = generate_PhysicalSegmentLayout(df_meta)\n",
    "ValueMapping = generate_ValueMapping(df, df_meta)\n",
    "ValueMappingPosition = generate_ValueMappingPosition(df_meta)\n",
    "InstanceValue = generate_InstanceValue(df, df_meta)\n",
    "DataPoint = generate_DataPoint(df, df_meta)\n",
    "DataPointPosition = generate_DataPointPosition(df, df_meta)\n",
    "DataStore = generate_DataStore(df_meta)\n",
    "WideDataSet = generate_WideDataSet(df_meta)\n",
    "WideDataStructure = generate_WideDataStructure(df_meta)\n",
    "PrimaryKey = generate_PrimaryKey(df_meta)\n",
    "PrimaryKeyComponent = generate_PrimaryKeyComponent(df_meta)\n",
    "MeasureComponent = generate_MeasureComponent(df_meta)\n",
    "IdentifierComponent = generate_IdentifierComponent(df_meta)\n",
    "\n",
    "\n",
    "json_ld_graph = DataStore + PhysicalDataset + PhysicalRecordSegment + PhysicalSegmentLayout + ValueMapping + \\\n",
    "ValueMappingPosition + DataPoint + DataPointPosition + InstanceValue + LogicalRecord + WideDataSet + \\\n",
    "WideDataStructure + IdentifierComponent + MeasureComponent + PrimaryKey + PrimaryKeyComponent + InstanceVariable + \\\n",
    "SubstantiveConceptualDomain + SubstantiveConceptScheme + SentinelConceptualDomain + ValueAndConceptDescription + \\\n",
    "SentinelConceptScheme + Concept"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1118950d-a1f6-4bb7-ac30-0fc2269359d4",
   "metadata": {},
   "source": [
    "## Create Json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23010e43-e449-41b9-8d68-c751cff7e051",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary with the specified \"@context\" and \"@graph\" keys\n",
    "json_ld_dict = {\n",
    "    \"@context\": [\n",
    "        \"https://ddi-alliance.bitbucket.io/DDI-CDI/DDI-CDI_v1.0-rc1/encoding/json-ld/ddi-cdi.jsonld\",\n",
    "        {\n",
    "            \"skos\": \"http://www.w3.org/2004/02/skos/core#\"\n",
    "        }\n",
    "    ],\n",
    "    \"@graph\": json_ld_graph\n",
    "}\n",
    "\n",
    "def default_encode(obj):\n",
    "    if isinstance(obj, np.int64):\n",
    "        return int(obj)\n",
    "    elif pd.isna(obj):  # Checks for pd.NA\n",
    "        return None\n",
    "    elif isinstance(obj, pd.Timestamp):  # Checks for Timestamp\n",
    "        return obj.isoformat()\n",
    "    raise TypeError(f\"Object of type {obj.__class__.__name__} is not JSON serializable\")\n",
    "\n",
    "\n",
    "\n",
    "# Convert the Python dictionary to a JSON string with pretty formatting\n",
    "\n",
    "json_ld_string = json.dumps(json_ld_dict, indent=4, default=default_encode)\n",
    "# New code to write the JSON-LD string to a file\n",
    "with open('output.jsonld', 'w') as file:\n",
    "    file.write(json_ld_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f29306f-faec-430f-880b-dd69375054ba",
   "metadata": {},
   "source": [
    "##### "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
